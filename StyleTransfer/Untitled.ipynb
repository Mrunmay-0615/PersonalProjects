{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"two convolution layers with batch norm and leaky relu\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_p):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_conv(x)\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"Downsampling followed by ConvBlock\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_p):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlock(in_channels, out_channels, dropout_p)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"Upssampling followed by ConvBlock\"\"\"\n",
    "    def __init__(self, in_channels1, in_channels2, out_channels, dropout_p):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels1, in_channels2, kernel_size=1)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = ConvBlock(in_channels2 * 2, out_channels, dropout_p)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.conv1x1(x1)\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.params = params\n",
    "        self.in_chns = self.params['in_chns']\n",
    "        self.ft_chns = self.params['feature_chns']\n",
    "        self.dropout = self.params['dropout']\n",
    "        assert (len(self.ft_chns) == 5)\n",
    "        self.in_conv = ConvBlock(\n",
    "            self.in_chns, self.ft_chns[0], self.dropout[0])\n",
    "        self.down1 = DownBlock(\n",
    "            self.ft_chns[0], self.ft_chns[1], self.dropout[1])\n",
    "        self.down2 = DownBlock(\n",
    "            self.ft_chns[1], self.ft_chns[2], self.dropout[2])\n",
    "        self.down3 = DownBlock(\n",
    "            self.ft_chns[2], self.ft_chns[3], self.dropout[3])\n",
    "        self.down4 = DownBlock(\n",
    "            self.ft_chns[3], self.ft_chns[4], self.dropout[4])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.in_conv(x)\n",
    "        x1 = self.down1(x0)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        return x4, [x0, x1, x2, x3, x4]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.params = params\n",
    "        self.in_chns = self.params['in_chns']\n",
    "        self.ft_chns = self.params['feature_chns']\n",
    "        assert (len(self.ft_chns) == 5)\n",
    "\n",
    "        self.up1 = UpBlock(self.ft_chns[4], self.ft_chns[3], self.ft_chns[3], dropout_p=0.0)\n",
    "        self.up2 = UpBlock(self.ft_chns[3], self.ft_chns[2], self.ft_chns[2], dropout_p=0.0)\n",
    "        self.up3 = UpBlock(self.ft_chns[2], self.ft_chns[1], self.ft_chns[1], dropout_p=0.0)\n",
    "        self.up4 = UpBlock(self.ft_chns[1], self.ft_chns[0], self.ft_chns[0], dropout_p=0.0)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(self.ft_chns[0], self.in_chns, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        x0 = feature[0]\n",
    "        x1 = feature[1]\n",
    "        x2 = feature[2]\n",
    "        x3 = feature[3]\n",
    "        x4 = feature[4]\n",
    "\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x_last = self.up4(x, x0)\n",
    "        output = self.out_conv(x_last)\n",
    "        return output, x_last\n",
    "    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        params = {'in_chns': in_channels,\n",
    "                  'feature_chns': [16, 32, 64, 128, 256],\n",
    "                  'dropout': [0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "                  'acti_func': 'relu'}\n",
    "\n",
    "        self.encoder = Encoder(params)\n",
    "        self.decoder = Decoder(params)\n",
    "        dim_in = 16\n",
    "        feat_dim = 32\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        _, feature = self.encoder(x)\n",
    "        output, features = self.decoder(feature)\n",
    "        return torch.sigmoid(output)\n",
    "    \n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,\n",
    "                      out_channels,\n",
    "                      kernel_size,\n",
    "                      stride,\n",
    "                      padding,\n",
    "                      padding_mode='reflect',\n",
    "                      bias=True),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, features=(64, 128, 256, 512)):\n",
    "        super().__init__()\n",
    "        self.initial_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=features[0],\n",
    "                      kernel_size=4,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(Block(in_channels=in_channels,\n",
    "                                out_channels=feature,\n",
    "                                kernel_size=4,\n",
    "                                stride= 1 if feature == features[-1] else 2,\n",
    "                                padding=1,\n",
    "            ))\n",
    "            in_channels = feature\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels,\n",
    "                                1, 4, 1, 1, padding_mode='reflect'))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_layer(x)\n",
    "        return torch.sigmoid(self.model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "####-----------Define the dataloaders and dataset class-------------####\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class monet2photo(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        super().__init__()\n",
    "        self.root_monet = os.path.join(root_dir, 'trainA')\n",
    "        self.root_photos = os.path.join(root_dir, 'trainB')\n",
    "\n",
    "        self.monet_images = os.listdir(self.root_monet)\n",
    "        self.photo_images = os.listdir(self.root_photos)\n",
    "\n",
    "        self.length = max(len(self.monet_images), len(self.photo_images))\n",
    "        self.monet_len = len(self.monet_images)\n",
    "        self.photo_len = len(self.photo_images)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        photo_img = Image.open(os.path.join(self.root_photos, self.photo_images[index % self.photo_len])).convert('RGB')\n",
    "        monet_img = Image.open(os.path.join(self.root_monet, self.monet_images[index % self.monet_len])).convert('RGB')\n",
    "\n",
    "        photo_img = np.array(photo_img) / 255.\n",
    "        monet_img = np.array(monet_img) / 255.\n",
    "        photo_img, monet_img = photo_img.astype(np.float32), monet_img.astype(np.float32)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            photo_img = self.transform(photo_img)\n",
    "            monet_img = self.transform(monet_img)\n",
    "\n",
    "        return monet_img, photo_img\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "import random, torch, os, numpy as np\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import Compose, Resize, RandomHorizontalFlip, Normalize, ToTensor\n",
    "\n",
    "# Hyperparameters and configs\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available else 'cpu'\n",
    "root_dir = 'monet2photo'\n",
    "batch_size = 8\n",
    "lr_rate = 1e-4\n",
    "lambda_identity = 5\n",
    "lambda_cycle = 10\n",
    "num_epochs = 50\n",
    "load_model = False\n",
    "save_model = True\n",
    "monet_generator = 'monet_gen.pth.tar'\n",
    "photo_generator = 'photo_gen.pth.tar'\n",
    "monet_discriminator = 'monet_dis.pth.tar'\n",
    "photo_discriminator = 'photo_dis.pth.tar'\n",
    "num_workers = 4\n",
    "transforms = Compose(\n",
    "    [\n",
    "        ToTensor(),\n",
    "        Resize(size=(256, 256)),\n",
    "        RandomHorizontalFlip(p=0.5),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The training loop\n",
    "def train_step(disc_y, disc_x, gen_ytox, gen_xtoy, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler):\n",
    "    loop = tqdm(loader)\n",
    "    y_reals = 0\n",
    "    y_fakes = 0\n",
    "    gen_loss = 0.0\n",
    "    disc_loss = 0.0\n",
    "    for batch_idx, (x, y) in enumerate(loop):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # First train the discriminators\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake_y = gen_xtoy(x)\n",
    "            dy_fake = disc_y(fake_y.detach())\n",
    "            dy_real = disc_y(y)\n",
    "            y_reals += dy_real.mean().item()\n",
    "            y_fakes += dy_fake.mean().item()\n",
    "            discy_real_loss = mse(dy_real, torch.ones_like(dy_real))\n",
    "            discy_fake_loss = mse(dy_fake, torch.zeros_like(dy_fake))\n",
    "            discy_loss = (discy_real_loss + discy_fake_loss) / 2\n",
    "\n",
    "            fake_x = gen_ytox(y)\n",
    "            dx_fake = disc_x(fake_x.detach())\n",
    "            dx_real = disc_x(x)\n",
    "            discx_real_loss = mse(dx_real, torch.ones_like(dx_real))\n",
    "            discx_fake_loss = mse(dx_fake, torch.zeros_like(dx_fake))\n",
    "            discx_loss = (discx_real_loss + discx_fake_loss) / 2\n",
    "\n",
    "            D_loss = discy_loss + discx_loss\n",
    "        opt_disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "\n",
    "        # Train generators\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # 1. Adversarial Loss\n",
    "            discx_fake = disc_x(fake_x)\n",
    "            discy_fake = disc_y(fake_y)\n",
    "            loss_g_xtoy = mse(discy_fake, torch.ones_like(discy_fake))\n",
    "            loss_g_ytox = mse(discx_fake, torch.ones_like(discx_fake))\n",
    "            adv_G_loss = loss_g_ytox + loss_g_xtoy\n",
    "\n",
    "            # 2. Cycle-consistency loss\n",
    "            cycle_xtoytox = gen_ytox(fake_y)\n",
    "            cycle_ytoxtoy = gen_xtoy(fake_x)\n",
    "            cycle_x_loss = L1(cycle_xtoytox, x)\n",
    "            cycle_y_loss = L1(cycle_ytoxtoy, y)\n",
    "            cycle_G_loss = cycle_x_loss + cycle_y_loss\n",
    "\n",
    "            # 3. Identity loss\n",
    "            identity_x = gen_ytox(x)\n",
    "            identity_y = gen_xtoy(y)\n",
    "            identity_x_loss = L1(identity_x, x)\n",
    "            identity_y_loss = L1(identity_y, y)\n",
    "            identity_G_loss = identity_x_loss + identity_y_loss\n",
    "\n",
    "            # add all togethor\n",
    "            G_loss = adv_G_loss + lambda_cycle * cycle_G_loss + lambda_identity * identity_G_loss\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "\n",
    "        if batch_idx % 200 == 0:\n",
    "            if not os.path.exists(f\"saved_images/{batch_idx}\"):\n",
    "              os.mkdir(f\"saved_images/{batch_idx}\")\n",
    "            save_image(fake_y, f\"saved_images/{batch_idx}/fake_photo.png\")\n",
    "            save_image(fake_x, f\"saved_images/{batch_idx}/fake_monet.png\")\n",
    "            save_image(x, f\"saved_images/{batch_idx}/real_monet.png\")\n",
    "            save_image(y, f\"saved_images/{batch_idx}/real_photo.png\")\n",
    "\n",
    "        gen_loss += G_loss.item()\n",
    "        disc_loss += D_loss.item()\n",
    "        loop.set_postfix(y_real=y_reals / (batch_idx + 1), y_fake=y_fakes / (batch_idx + 1), gen_loss=gen_loss / (batch_idx+1), disc_loss = disc_loss/ (batch_idx+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 786/786 [12:11<00:00,  1.08it/s, disc_loss=0.429, gen_loss=3.03, y_fake=0.426, y_real=0.568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 786/786 [12:24<00:00,  1.06it/s, disc_loss=0.432, gen_loss=2.46, y_fake=0.417, y_real=0.573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 786/786 [12:22<00:00,  1.06it/s, disc_loss=0.411, gen_loss=2.42, y_fake=0.396, y_real=0.593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 786/786 [3:40:19<00:00, 16.82s/it, disc_loss=0.388, gen_loss=2.42, y_fake=0.381, y_real=0.611]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/786 [00:13<11:55,  1.08it/s, disc_loss=0.36, gen_loss=2.6, y_fake=0.375, y_real=0.63]  "
     ]
    }
   ],
   "source": [
    "disc_x = Discriminator(in_channels=3).to(device)\n",
    "disc_y = Discriminator(in_channels=3).to(device)\n",
    "gen_xtoy = Generator(in_channels=3).to(device)\n",
    "gen_ytox = Generator(in_channels=3).to(device)\n",
    "\n",
    "opt_disc = optim.Adam(\n",
    "    params = list(disc_x.parameters()) + list(disc_y.parameters()),\n",
    "    lr=lr_rate,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "opt_gen = optim.Adam(\n",
    "    params=list(gen_xtoy.parameters()) + list(gen_ytox.parameters()),\n",
    "    lr=lr_rate,\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "L1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "if load_model:\n",
    "    load_checkpoint(\n",
    "        photo_generator,\n",
    "        gen_xtoy,\n",
    "        opt_gen,\n",
    "        lr_rate,\n",
    "    )\n",
    "    load_checkpoint(\n",
    "        monet_generator,\n",
    "        gen_ytox,\n",
    "        opt_gen,\n",
    "        lr_rate,\n",
    "    )\n",
    "    load_checkpoint(\n",
    "        monet_discriminator,\n",
    "        disc_y,\n",
    "        opt_disc,\n",
    "        lr_rate,\n",
    "    )\n",
    "    load_checkpoint(\n",
    "        photo_discriminator,\n",
    "        disc_x,\n",
    "        opt_disc,\n",
    "        lr_rate,\n",
    "    )\n",
    "\n",
    "dataset = monet2photo(\n",
    "    root_dir=root_dir,\n",
    "    transform=transforms,\n",
    ")\n",
    "# val_dataset = HorseZebraDataset(\n",
    "#     root_horse=config.VAL_DIR + \"/horses\",\n",
    "#     root_zebra=config.VAL_DIR + \"/zebras\",\n",
    "#     transform=config.transforms,\n",
    "# )\n",
    "# val_loader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "if not os.path.exists('saved_images'):\n",
    "  os.mkdir('saved_images')\n",
    "\n",
    "print(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_step(\n",
    "        disc_y,\n",
    "        disc_x,\n",
    "        gen_ytox,\n",
    "        gen_xtoy,\n",
    "        loader,\n",
    "        opt_disc,\n",
    "        opt_gen,\n",
    "        L1,\n",
    "        mse,\n",
    "        d_scaler,\n",
    "        g_scaler,\n",
    "    )\n",
    "\n",
    "    if save_model:\n",
    "        save_checkpoint(gen_xtoy, opt_gen, filename=photo_generator)\n",
    "        save_checkpoint(gen_ytox, opt_gen, filename=monet_generator)\n",
    "        save_checkpoint(disc_y, opt_disc, filename=monet_discriminator)\n",
    "        save_checkpoint(disc_x, opt_disc, filename=photo_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
